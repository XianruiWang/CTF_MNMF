from mimetypes import init
from tkinter.messagebox import NO
import numpy as np
from basetool import *
from beamformer import *


def CTF_MNMF(X_FTM=None, n_iter=20, L_list=None, distribution="gauss", postFilter="MWF",lag=0, d_FNM=None, mic_index=0, n_components=3):
    """
    CTF_MNMF 1
    ======

    Blind source separation based on MNMF based on convolutive transfer function

    Parameters
    -------
    X_FTM: multichannel mixed data in frequency domain
    n_src: number of sources
    v_src: number of virtual sources
    n_iter: number of iterations
    L_list: [L_1, L_2, L_3, ..., L_N], L1+L2+...+L_N=M, L_n is the number of 
            virtual sources generated by the n true source

    Return
    -------
    YHat_FTN: estimated signal n_freq * n_frames * n_source

    References
    ----------
    .. [1]T. Wang, F. Yang, J. Yang, "Convolutive transfer function-based multichannel nonnegative matrix factorization for
          overdertermined blind source separation ", Trans. on Audio Speech and Lang. Porcess., vol. 30, pp. 802-815, 2022.
    ======
    """

    eps = 1e-18
    n_freq, n_frame, n_channel = X_FTM.shape
    # number of sources
    n_src = len(L_list)
    # number of virtual sources
    v_src = sum(L_list)
    L_max = max(L_list)
    # create a list to select true sources from virtual microphones
    L_select = [0] * n_src
    for l_index in range(1 ,n_src):
        L_select[l_index] = L_select[l_index-1] + L_list[l_index-1]
    L_select_extend = L_select.copy()
    L_select_extend.extend([v_src])

    # parameters check
    assert (v_src == n_channel), "The number of virtual sources should be equal to that of microphones"
    # L == M, eq. 46
    X_FTL = X_FTM
    X_FLT = X_FTL.transpose([0, 2, 1])


    # memory allocation
    eyes = np.tile(np.eye(n_channel, n_channel), (n_freq, 1, 1))
    W_FLL = np.tile(np.eye(v_src, v_src, dtype=X_FTM.dtype), (n_freq, 1, 1))
    H_FLL = np.tile(np.eye(v_src, v_src, dtype=X_FTM.dtype), (n_freq, 1, 1))
    loss_old = np.inf
    if d_FNM is not None:
        Cov_FMM = CovMat_estimation(X_FTM=X_FTM, Roubust=True)
        cons_src = d_FNM.shape[1]
        for n in range(np.minimum(n_src, cons_src)):
            W_FLL[:, L_select[n],:] = np.squeeze(MPDR_construct(steerVecSOI_FM1=d_FNM[:, n, :, None], CovMat_FMM=Cov_FMM)) 

    # separated true source
    # separated virtual source
    YvHat_FLT = np.zeros([n_freq, v_src, n_frame], dtype=X_FLT.dtype)
    YnHat_FNT = YvHat_FLT[:, L_select, :]
    T_NFK = np.random.rand(n_src, n_freq, n_components).astype(np.float64) + 0.1
    V_NKT = np.random.rand(n_src, n_components, n_frame).astype(np.float64) + 0.1
    lambda_FTN = (T_NFK @ V_NKT).transpose([1, 2, 0])
    lambda_FTN[lambda_FTN< eps] = eps
    lambda_FTL = np.repeat(lambda_FTN, L_list, axis=-1)
    lambda_inv_FTL = 1.0 / (lambda_FTL+eps)
    # This two dimension expanded tensor are used in eq. 29 & eq.30.  
    # Dimension expanded for using broadcasting
    Pv_reshape_FTNLmax = np.zeros([n_freq, n_frame, n_src, L_max]).astype(np.float64) + eps
    lambda_inv_reshape_FTNLmax = np.zeros([n_freq, n_frame, n_src, L_max]).astype(np.float64)
    V_extend_NKTLmax = np.zeros([n_src, n_components, n_frame, L_max]).astype(np.float64)


    def cal_loss():
        """
        calculate cost function
        """
        G_NT = np.sqrt(np.sum(np.abs(YvHat_FLT)**2, axis=0))
        G_N = np.mean(G_NT, axis=1)
        G = np.sum(G_N)
        lod_det = np.sum(np.log(np.abs(np.linalg.det(W_FLL))))
        loss = (G-lod_det)/(n_freq*n_src)
        loss_imp = np.abs(loss-loss_old)/abs(loss)
        loss_last = loss
        return loss, loss_last, loss_imp


    def separate():
        """
        separate virtual sources from observation
        """
        YvHat_FLT[:, :, :] = W_FLL @ X_FLT
        YnHat_FNT[:, :, :] = YvHat_FLT[:, L_select, :]
    separate()

    def lambda_FTL_construct():
        lambda_FTL[:, :, :] = np.repeat(lambda_FTN, L_list, axis=-1)
        lambda_inv_FTL[:, :, :] = 1.0 / (lambda_FTL+eps)
        for nindex in range(n_src):
            n_start = L_select[nindex]
            lambda_prime_FT = lambda_FTN[:, :, nindex]
            for sindex in range(1, L_list[nindex]):
                pos = n_start + sindex
                lambda_FTL[:, lag+sindex:, pos] = np.roll(lambda_prime_FT, lag+sindex, axis=1)[:, lag+sindex:]
                lambda_inv_FTL[:, lag+sindex:, pos] = np.roll(1.0/(lambda_prime_FT+eps), lag+sindex, axis=1)[:, lag+sindex:]
        lambda_FTL[lambda_FTL<eps] = eps
        lambda_inv_FTL[lambda_inv_FTL<eps] = eps


    def parameter_reshape():
        """
        This function reshape lambda_inv_FTL into lambda_inv_reshape_FTNLmax
        and Pv_FLT into Pv_reshape_FTNLmax.
        All redundant dimensions are padded with zeros in order to broadcasting
        """
        lambda_FTL_construct()
        Pv_FLT = np.abs(YvHat_FLT) ** 2
        Pv_FTL = Pv_FLT.transpose([0, 2, 1])
        for n_index in range(n_src):
            L_n = L_list[n_index]
            Pv_reshape_FTNLmax[:, :, n_index, :L_n] = Pv_FTL[..., L_select_extend[n_index]:L_select_extend[n_index+1]]
            lambda_inv_reshape_FTNLmax[:, :, n_index, :L_n] = lambda_inv_FTL[..., L_select_extend[n_index]:L_select_extend[n_index+1]]        

    
    def V_extend_NKTLmax_construct():
        for nindex in range(n_src):
            V_prime_KT = V_NKT[nindex]
            for sindex in range(1, L_list[nindex]):
                V_extend_NKTLmax[nindex, :, lag+sindex:, sindex] = np.roll(V_prime_KT, lag+sindex, axis=1)[:, lag+sindex:]


    # update NMF model
    def NMF_update():
        parameter_reshape()
        V_extend_NKTLmax_construct()
        V_extend_KTNLmax = V_extend_NKTLmax.transpose([1, 2, 0, 3])
        # eq. 29
        T_update_numer_FKN = np.squeeze(np.sum(Pv_reshape_FTNLmax[:, None] * V_extend_KTNLmax[None] * (lambda_inv_reshape_FTNLmax[:, None]**2), axis=(2,4)))
        T_update_denom_FKN = np.squeeze(np.sum(V_extend_KTNLmax[None] * lambda_inv_reshape_FTNLmax[:, None], axis=(2,4)))
        T_NFK[:, :, :] *= (T_update_numer_FKN * (1.0/(T_update_denom_FKN+eps))).transpose([2, 0, 1])
        # eq. 30
        lambda_FTN[:, :, :] = (T_NFK @ V_NKT).transpose([1, 2, 0])
        lambda_inv_FTN = 1.0 /(lambda_FTN+eps)
        Pn_FNT = np.abs(YnHat_FNT) ** 2
        Pn_FTN = Pn_FNT.transpose([0, 2, 1])
        T_FKN = T_NFK.transpose([1, 2, 0])
        V_update_numer_TKN = np.squeeze(np.sum(Pn_FTN[:, :, None] * T_FKN[:, None] * (lambda_inv_FTN[:, :, None]**2), axis=0))
        V_update_denom_TKN = np.squeeze(np.sum(T_FKN[:, None] * lambda_inv_FTN[:, :, None], axis=0))
        V_NKT[:, :, :] *= (V_update_numer_TKN * (1.0/(V_update_denom_TKN+eps))).transpose([2, 1, 0])
        lambda_FTN[:, :, :] = (T_NFK @ V_NKT).transpose([1, 2, 0])
        lambda_FTL_construct()


    def spatialFilter_update():
        lambda_inv_FLT = lambda_inv_FTL.transpose([0, 2, 1])
        for vindex in range(v_src):
            V_FLL = (X_FLT * lambda_inv_FLT[:, vindex, None, :] @ np.conj(X_FLT.swapaxes(1,2)))/n_frame
            WV_FLL = np.matmul(W_FLL, V_FLL)
            u = np.linalg.solve(WV_FLL+eps*eyes, eyes[:, :, vindex])  # eq. 36
            u_temp1 = np.sqrt(np.matmul(np.matmul(np.conj(u[:, None, :]), V_FLL),
                                        u[:, :, None]))
            u_temp2 = (u[:, :, None]/u_temp1)[:, :, 0]
            W_FLL[:, vindex, :] = np.conj(u_temp2)

    
    def normalization():
        for nindex in range(n_src):
            # eq. 39
            YvHat_n_FLnT = YvHat_FLT[:, L_select_extend[nindex]:L_select_extend[nindex+1], :]
            mu_n_Ln = np.sqrt(np.mean(np.abs(YvHat_n_FLnT) ** 2, axis=(0,2), keepdims=False))
            # eq. 40
            YvHat_FLT[:, L_select_extend[nindex]:L_select_extend[nindex+1], :] *= (1.0 / (mu_n_Ln+eps))[None, :, None]
            # eq. 41
            W_FLL[:, L_select_extend[nindex]:L_select_extend[nindex+1], :] *= (1.0 / (mu_n_Ln+eps))[None, :, None]
            # eq. 42
            lambda_FTL[:, :, L_select_extend[nindex]:L_select_extend[nindex+1]] *= (1.0 / ((mu_n_Ln+eps)**2))[None, None]
            # eq. 43
            T_NFK[nindex] *= (1.0/(mu_n_Ln+eps)**2)[0]
            lambda_FTN[:, :, :] = (T_NFK @ V_NKT).transpose([1, 2, 0])
        YnHat_FNT[:, :, :] = YvHat_FLT[:, L_select, :]


    spec_FTN = np.zeros((n_freq, n_frame, n_src), dtype=X_FLT.dtype)
    def postfiltering():
        if postFilter=="MWF":
            lambda_FTL_construct()
            H_FLL = np.linalg.pinv(W_FLL)    
            Q_inv_FTLL = (np.conj(W_FLL.swapaxes(1,2))[:, None] / lambda_FTL[:, :, None]) @ W_FLL[:, None]
            for n in range(n_src):
                L_start = L_select_extend[n]
                L_end = L_select_extend[n+1]
                lambda_n_FTLn = lambda_FTL[:, :, L_start:L_end]
                H_n_FLLn = H_FLL[:, :, L_start:L_end]
                Q_n_FTLL = H_n_FLLn[:, None] * lambda_n_FTLn[:, :, None] @ np.conj(H_n_FLLn.swapaxes(1,2))[:, None]
                spec_FTN[:, :, n] = np.squeeze(((Q_n_FTLL @ Q_inv_FTLL) @ X_FTL[..., None])[:, :, mic_index, 0])
            return spec_FTN
        else:
            separate()
            YHat_TFN = YnHat_FNT.transpose([2, 0, 1])
            spec_FT = X_FTM[:,:,0]
            X_TF = spec_FT.T
            Z = projection_back(YHat_TFN, X_TF)
            YHat_TFN *= np.conj(Z[None, :, :])
            spec_FTN[:, :, :] = YHat_TFN.transpose([1, 0, 2])
            return spec_FTN

    for epoch in range(n_iter):
        NMF_update()
        spatialFilter_update()
        separate()
        normalization()
    normalization()
    postfiltering()
    return spec_FTN